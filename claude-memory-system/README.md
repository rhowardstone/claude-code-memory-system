# Claude Code Memory System V7

**Intelligent memory preservation system with contextual embeddings, knowledge graphs, and task-context awareness.**

Stop losing context when your conversations get compacted! This system automatically extracts, scores, and preserves important memories from your coding sessions, then intelligently injects the most relevant ones back using contextual embeddings, knowledge graph traversal, and task-context scoring.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸŒŸ Features

### V7: Contextual Embeddings + Last Actions
- **ğŸ¯ "Where You Left Off"**: Shows last 5 actions, files, and status before compaction (the "50 First Dates" solution!)
- **ğŸ“ Contextual Embeddings**: Prepends session/time/file context to embeddings for better retrieval
- **â° Temporal Queries**: Find "yesterday's work" or "last week's changes" naturally
- **ğŸ“ File-Context Queries**: Search "auth.py changes" or "modifications to utils.py"
- **ğŸ“Š Evaluation Framework**: Precision, Recall, F1, MRR metrics for measuring quality
- **âœ… Test Suite**: 293 tests, 49% coverage across critical components

### V6: Clean Architecture + Centralized Versioning
- **ğŸ“¦ No Version Suffixes**: Clean filenames (precompact.py, not precompact_v2.py)
- **ğŸ”¢ Centralized Versions**: All versions tracked in __version__.py
- **ğŸ“‹ Proper Semantic Versioning**: Major.Minor.Patch format

### V5: Knowledge Graph + Task-Context Awareness
- **ğŸ•¸ï¸ Knowledge Graph**: Automatically extracts entities (files, functions, bugs, features) and builds relationship graph
- **ğŸ¯ Task-Context Scoring**: Boosts memories relevant to current work (1.5-3x importance)
- **ğŸ“ˆ PageRank Centrality**: Identifies most important entities across conversations
- **ğŸ”— Multi-Hop Traversal**: Finds related memories through graph relationships (1-2 hops)
- **ğŸ“Š Adaptive K Retrieval**: Returns 0-20 memories dynamically based on quality (not fixed top-K!)

### V4: Full Transcripts + Better Embeddings
- **ğŸ“ Full Transcript Storage**: No truncation! Complete intent/action/outcome preserved
- **ğŸš€ nomic-embed-text-v1.5**: 768-dim embeddings with 8192 token context (16x better than old model!)
- **ğŸ¨ Hierarchical Display**: Short summaries for injection, full transcripts via query tool
- **âš¡ 85% Relevance Improvement**: Task-relevant queries: 72% vs 39% with old system

### Core Memory System
- **ğŸ§  Smart Chunking**: Automatically breaks conversations into Intent-Action-Outcome triplets
- **â­ Importance Scoring**: 10+ signals identify critical memories (decisions, fixes, learnings)
- **ğŸ¯ Vector Search**: Fast semantic retrieval with HNSW indexing (ChromaDB)
- **ğŸ”„ Auto-Pruning**: Removes old/redundant memories based on age, similarity, and capacity
- **ğŸ“Š Hierarchical Clustering**: Organizes related memories into topical groups

### Multi-Modal Artifacts
Automatically extracts and indexes:
- ğŸ’» **Code snippets** with language tags
- ğŸ“ **File paths** modified/created
- ğŸ—ï¸ **Architecture discussions** and design decisions
- âš™ï¸ **Commands executed**
- âŒ **Error messages** and troubleshooting
- ğŸ”§ **Tools used** (Read, Write, Edit, Bash, etc.)

### No API Costs
- **100% Local**: Uses sentence-transformers for embeddings (nomic-embed-text-v1.5)
- **No API calls**: Smart rule-based chunking (no LLM needed)
- **Offline-first**: Works without internet connection

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- Claude Code CLI
- ~500MB disk space (for dependencies)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/rhowardstone/claude-code-memory-system.git
cd claude-code-memory-system

# Run installer (safely updates settings.json)
./install.sh
```

The installer will:
1. Copy hooks to `~/.claude/memory-hooks/`
2. Install Python dependencies (chromadb, sentence-transformers, etc.)
3. Update `~/.claude/settings.json` with hook configuration
4. Create memory database directory

### Manual Installation

If you prefer manual setup, see [docs/INSTALLATION.md](docs/INSTALLATION.md).

---

## ğŸš€ How It Works

### The Memory Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Normal Coding Session                     â”‚
â”‚  You work with Claude Code, creating files, fixing bugs...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Context fills up
                         â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  /compact    â”‚
                  â”‚   triggers   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     PreCompact Hook Fires          â”‚
        â”‚  â€¢ Loads conversation transcript   â”‚
        â”‚  â€¢ Smart chunking (IAO triplets)   â”‚
        â”‚  â€¢ Importance scoring              â”‚
        â”‚  â€¢ Multi-modal extraction          â”‚
        â”‚  â€¢ Stores in vector DB             â”‚
        â”‚  â€¢ Auto-prunes old memories        â”‚
        â”‚  â€¢ Creates hierarchical clusters   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Compaction     â”‚
               â”‚  (Claude Code's  â”‚
               â”‚   internal)      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    SessionStart Hook Fires         â”‚
        â”‚  â€¢ Retrieves 5 recent important    â”‚
        â”‚  â€¢ Retrieves 10 relevant (vector)  â”‚
        â”‚  â€¢ Combines importance + relevance â”‚
        â”‚  â€¢ Injects via additionalContext   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      New Session Starts            â”‚
        â”‚  Claude sees previous memories!    â”‚
        â”‚  Continuity preserved across gap   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Gets Preserved?

**Automatically scored by importance:**
- ğŸ”´ **Critical (20+)**: Architectural decisions, major bug fixes, key learnings
- ğŸŸ  **High (10-20)**: File creations, test successes, important changes
- ğŸŸ¡ **Medium (5-10)**: Code snippets, moderate edits, context
- ğŸŸ¢ **Low (<5)**: Routine work, minor changes

**Example memories:**
```json
{
  "intent": "Fix authentication bug causing 401 errors",
  "action": "Modified auth.ts to properly handle token expiry, added refresh logic",
  "outcome": "Tests passing, bug resolved",
  "importance": 24.5,
  "artifacts": {
    "files": ["src/auth.ts", "tests/auth.test.ts"],
    "code_snippets": ["async function refreshToken() { ... }"],
    "architecture": ["token refresh flow"]
  }
}
```

---

## ğŸ¯ Usage

### Automatic Usage (Recommended)

Just use Claude Code normally! Memories are automatically:
1. **Extracted** when compaction triggers (PreCompact hook)
2. **Injected** when session resumes after compaction (SessionStart hook)

### CLI Tools

Browse and search your memories anytime with `query_memories.py`:

```bash
# View statistics
python3 ~/.claude/memory-hooks/query_memories.py --stats

# Search by topic (semantic)
python3 ~/.claude/memory-hooks/query_memories.py --topic "authentication bug fix"

# Search by keywords
python3 ~/.claude/memory-hooks/query_memories.py --keywords error crash failed

# High importance only
python3 ~/.claude/memory-hooks/query_memories.py --min-importance 15

# Find files involved in errors
python3 ~/.claude/memory-hooks/query_memories.py --files-involved --keywords bug

# Date range search
python3 ~/.claude/memory-hooks/query_memories.py --since "2025-10-12" --until "2025-10-13"

# Session-specific
python3 ~/.claude/memory-hooks/query_memories.py --session current --topic "recent work"

# Detailed output
python3 ~/.claude/memory-hooks/query_memories.py --topic "testing" --format detailed

# JSON output for scripting
python3 ~/.claude/memory-hooks/query_memories.py --topic "bugs" --format json
```

### Example Output

```
ğŸ“Š Memory Statistics
================================================================================
Total memories: 42
Average importance: 16.8

Importance Distribution:
  ğŸŸ¢ Low       :    3 (  7.1%) â–ˆ
  ğŸŸ¡ Medium    :    5 ( 11.9%) â–ˆâ–ˆ
  ğŸŸ  High      :   28 ( 66.7%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  ğŸ”´ Critical  :    6 ( 14.3%) â–ˆâ–ˆ

Multi-modal Content:
  ğŸ’» Has code: 18 (42.9%)
  ğŸ“ Has files: 32 (76.2%)
  ğŸ—ï¸  Has architecture: 8 (19.0%)
```

---

## âš™ï¸ Configuration

### Tuning Importance Scoring

Edit `~/.claude/memory-hooks/memory_scorer.py`:

```python
WEIGHTS = {
    "decision_marker": 10.0,      # "decided to", "chose"
    "error_resolution": 8.0,       # "fixed", "resolved"
    "file_creation": 6.0,          # New files created
    "test_success": 5.0,           # Tests passing
    "learning": 7.0,               # "learned", "discovered"
    # ... adjust as needed
}
```

### Tuning Memory Retrieval

Edit `~/.claude/memory-hooks/sessionstart_memory_injector.py`:

```python
TOP_K_MEMORIES = 20           # Maximum memories (adaptive returns 0-20)
RECENT_MEMORIES = 4            # Recent chronological
MIN_IMPORTANCE = 5.0           # Minimum score to inject
MIN_SIMILARITY = 0.35          # Minimum relevance threshold
KG_CACHE_TTL = 300            # Knowledge graph cache lifetime (seconds)
```

### Tuning Auto-Pruning

Edit `~/.claude/memory-hooks/memory_pruner.py`:

```python
MAX_MEMORIES_PER_SESSION = 500  # Capacity limit
OLD_MEMORY_DAYS = 90            # Age threshold
LOW_IMPORTANCE_THRESHOLD = 3.0  # Importance cutoff
REDUNDANCY_THRESHOLD = 0.95     # Similarity for dedup
```

### Tuning Chunking

Edit `~/.claude/memory-hooks/precompact_memory_extractor.py`:

```python
MAX_TRANSCRIPT_MESSAGES = 1000  # Max messages to process
AUTO_PRUNE = True               # Auto-prune on compaction
```

---

## ğŸ“Š Architecture

### Components

```
~/.claude/
â”œâ”€â”€ memory-hooks/
â”‚   â”œâ”€â”€ precompact_memory_extractor.py      # V4: Full transcript extraction
â”‚   â”œâ”€â”€ sessionstart_memory_injector.py     # V5: Task-context aware injection
â”‚   â”œâ”€â”€ entity_extractor.py                 # Entity extraction
â”‚   â”œâ”€â”€ knowledge_graph.py                  # Graph construction
â”‚   â”œâ”€â”€ task_context_scorer.py              # Task-context scoring
â”‚   â”œâ”€â”€ query_memories.py                   # CLI query interface
â”‚   â”œâ”€â”€ memory_scorer.py                    # Importance calculation
â”‚   â”œâ”€â”€ multimodal_extractor.py             # Artifact extraction
â”‚   â”œâ”€â”€ memory_pruner.py                    # Auto-pruning logic
â”‚   â”œâ”€â”€ memory_clustering.py                # Hierarchical clustering
â”‚   â””â”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ memory_db/                              # ChromaDB storage
â”‚   â””â”€â”€ (vector database files)
â””â”€â”€ settings.json                           # Hook configuration
```

### Data Flow

1. **Extraction (PreCompact)**:
   - Transcript â†’ Format â†’ Smart chunk â†’ Score â†’ Extract artifacts â†’ Embed â†’ Store

2. **Retrieval (SessionStart)**:
   - Query â†’ Vector search + Recent filter â†’ Rank by importance Ã— relevance â†’ Format â†’ Inject

3. **Pruning (Automatic)**:
   - Age-based: Old + low importance
   - Redundancy: Near-duplicates (>95% similarity)
   - Capacity: Keep top N by importance

---

## ğŸ› Troubleshooting

### Debug Logs

All operations are logged to `~/.claude/memory_hooks_debug.log`:

```bash
tail -f ~/.claude/memory_hooks_debug.log
```

### Common Issues

**"No memories found"**
- Haven't run `/compact` yet
- Hooks not configured correctly in settings.json
- Check: `cat ~/.claude/settings.json | grep hooks`

**"Import errors"**
- Missing dependencies
- Fix: `pip install -r ~/.claude/memory-hooks/requirements.txt`

**"Hooks not firing"**
- Check settings.json format (must use array with matcher)
- Ensure scripts are executable: `chmod +x ~/.claude/memory-hooks/*.py`
- Check debug log for errors

**"Too few memories extracted"**
- Increase MAX_TRANSCRIPT_MESSAGES in precompact_memory_extractor.py
- Adjust chunking thresholds for more granular chunks

**"Too many memories"**
- Lower MAX_MEMORIES_PER_SESSION in memory_pruner.py
- Raise MIN_IMPORTANCE in sessionstart_memory_injector.py
- Run manual pruning (see memory_pruner.py)

---

## ğŸ”¬ Technical Details

### Embeddings (V4 Upgrade)
- **Model**: `nomic-ai/nomic-embed-text-v1.5` (768 dimensions)
- **Context**: 8192 tokens (16x better than old 512-token model!)
- **Size**: ~140MB
- **Speed**: ~500 embeddings/sec on CPU
- **Quality**: Ranks with top-10 models 70x bigger; perfect for code!
- **Upgrade**: 85% relevance improvement over old all-MiniLM-L6-v2

### Vector Database
- **Engine**: ChromaDB with HNSW indexing
- **Distance**: Cosine similarity
- **Indexing**: Automatic on insert
- **Storage**: Persistent local disk

### Importance Scoring Signals
1. Decision markers ("decided", "chose", "will use")
2. Error resolution ("fixed", "resolved", "debugged")
3. File operations (created, modified)
4. Test success (tests passing)
5. Learning indicators ("learned", "discovered")
6. Tool usage count
7. Code presence
8. Architecture discussions
9. Recency (exponential decay)
10. Session context

### Chunking Strategy
- Natural boundaries: File operations, decisions, topic changes
- Grouped operations: 3-5 related file writes
- Size limits: Intent (500 chars), Action (1000 chars), Outcome (300 chars)
- Deduplication: Skip empty/duplicate chunks

---

## ğŸ“š Examples

See [examples/](examples/) directory for:
- Real conversation memory extracts
- CLI usage examples
- Integration patterns
- Custom scoring configurations

---

## ğŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md).

### Development Setup

```bash
# Clone and install in dev mode
git clone https://github.com/rhowardstone/claude-code-memory-system.git
cd claude-code-memory-system
pip install -r hooks/requirements.txt

# Test installation
./install.sh
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built for [Claude Code](https://claude.ai/claude-code)
- Uses [ChromaDB](https://www.trychroma.com/) for vector storage
- Embeddings from [sentence-transformers](https://www.sbert.net/)
- Inspired by human episodic memory systems

---

## ğŸ“® Support

- **Issues**: [GitHub Issues](https://github.com/rhowardstone/claude-code-memory-system/issues)
- **Discussions**: [GitHub Discussions](https://github.com/rhowardstone/claude-code-memory-system/discussions)
- **Documentation**: [docs/](docs/)

---

## ğŸ—ºï¸ Roadmap

- [ ] Cross-session memory (with explicit user permission)
- [ ] Memory visualization dashboard
- [ ] Custom scoring rules via config file
- [ ] Memory export formats (Markdown, HTML, PDF)
- [ ] Integration with external knowledge bases
- [ ] Multi-language support for code artifacts
- [ ] Compression for very old memories
- [ ] Collaborative memory sharing (team features)

---

**Built with â¤ï¸ for the Claude Code community**
